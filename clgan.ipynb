{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xCvs6PGcs30"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CIbT0SScs4C",
        "outputId": "6d112759-c8ad-4411-ce85-8bdc44ad3145"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from torchsummary import summary\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "manualSeed = 999\n",
        "manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u2X7wyuXxqRo",
        "outputId": "2bbe6b02-a0d3-499c-9353-be1a72812585"
      },
      "outputs": [],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4jnzupwp1Fi"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/dataset_org/'\n",
        "org = '/content/PlantVillage-Dataset/raw/color/'\n",
        "\n",
        "os.mkdir(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXRnvc9Jwzom",
        "outputId": "e4838b09-e2a5-49c5-ff1d-f9c245e659e1"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "names = [os.path.basename(x) for x in glob(f'{org}Corn*')]\n",
        "names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HP5uwHGGrY_K"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import regex as reg\n",
        "import glob\n",
        "\n",
        "for k, i in enumerate(glob.iglob(f'{org}Corn*')):\n",
        "  destination = shutil.copytree(i, PATH+names[k])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr3ggUoWxrBC",
        "outputId": "e2ac7862-f83b-4abd-f63c-19bf0fab20d3"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "data_dir = pathlib.Path('/content/dataset_org')\n",
        "print(type(data_dir))\n",
        "print(data_dir)\n",
        "image_count = len(list(data_dir.glob('*/*.JPG')))\n",
        "l = list(data_dir.glob('*/*.JPG'))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fxw2Iwuvcs4E"
      },
      "outputs": [],
      "source": [
        "dataroot = PATH\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 32\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 64\n",
        "image_size256 = 256\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 30\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0001\n",
        "\n",
        "# Beta1 and Beta2 hyperparam for Adam optimizers\n",
        "beta1 = 0.9\n",
        "beta2 = 0.99\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "kMm52jIOcs4J",
        "outputId": "11651330-b8a5-435f-a0d2-e98b2c4fc79b"
      },
      "outputs": [],
      "source": [
        "dataset = dset.ImageFolder(root=dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "2aYkMMzfmlj8",
        "outputId": "cf98bbbb-9b72-4510-f194-e2acd66c5826"
      },
      "outputs": [],
      "source": [
        "dataset256 = dset.ImageFolder(root=dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size256),\n",
        "                               transforms.CenterCrop(image_size256),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "dataloader256 = torch.utils.data.DataLoader(dataset256, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "\n",
        "real_batch = next(iter(dataloader256))\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOi4U6jrcs4N"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUEcmKY48_-v"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Generator64(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator64, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d( nc, ngf , 9, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf , 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ngf , ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d( ngf, ngf * 2, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d( ngf * 2, ngf, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Conv2d( ngf, nc, 3, 1,padding = \"same\", bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QrZUJRv8_-v",
        "outputId": "bbf4e60b-88ae-4c47-a279-16267e5c5ac6"
      },
      "outputs": [],
      "source": [
        "netG64 = Generator64(ngpu).to(device)\n",
        "summary(netG64, (3,64,64))\n",
        "\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG64 = nn.DataParallel(netG64, list(range(ngpu)))\n",
        "\n",
        "netG64.apply(weights_init)\n",
        "\n",
        "print(netG64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0yWK9u0cs4U"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf*4, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf*4, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Flatten(1),\n",
        "            nn.Linear(1,1),\n",
        "            nn.Sigmoid()\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJhtH3gJcs4V",
        "outputId": "336ea176-e662-4f7e-9d9c-0b63ada272ed"
      },
      "outputs": [],
      "source": [
        "netD = Discriminator(ngpu).to(device)\n",
        "summary(netD, (3,64,64))\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "    \n",
        "netD.apply(weights_init)\n",
        "\n",
        "print(netD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "semoZvDs6uBU"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, 3, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcgS6jhP6uDo",
        "outputId": "7a864427-1f61-4af0-a1e6-39146c8becb1"
      },
      "outputs": [],
      "source": [
        "netEn = Encoder(ngpu).to(device)\n",
        "summary(netEn, (3,256,256))\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netEn = nn.DataParallel(netEn, list(range(ngpu)))\n",
        "    \n",
        "netEn.apply(weights_init)\n",
        "\n",
        "print(netEn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdGPbroF6uF-"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d( nc, ngf, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.Upsample(scale_factor = 2),\n",
        "            nn.ConvTranspose2d(ngf, ngf * 2, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Upsample(scale_factor = 2),\n",
        "\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf * 2, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d( ngf * 2, 3, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYL1Lqgf6uIU",
        "outputId": "d7ea435d-a09d-4edd-ac97-ec1a96f969d5"
      },
      "outputs": [],
      "source": [
        "netDec = Decoder(ngpu).to(device)\n",
        "summary(netDec, (3,64,64))\n",
        "\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netDec = nn.DataParallel(netDec, list(range(ngpu)))\n",
        "\n",
        "netDec.apply(weights_init)\n",
        "\n",
        "print(netDec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuQaXsiecs4W"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdVcrZkUEUyw"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import vgg19\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        vgg19_model = vgg19(pretrained=True)\n",
        "        self.feature_extractor = nn.Sequential(*list(vgg19_model.features.children())[:18])\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.feature_extractor(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "2185f33f8fc64e5aa0a6a458450ffee6",
            "66581b66da7e473288a079b5ddc62edd",
            "7e6963a5c09144d48cb4c7e5678c19e6",
            "48ac700288a74cae9f54fd131e2ca317",
            "e8919e251123426ca688aa985bd59202",
            "b126f8c8ce1b42c0865519b200f0b4f0",
            "ad2c75e53fb44983bd7d9d8720184db3",
            "0a693b4244314036ba6d384f64ee3199",
            "f1eee1fd4c014a8babc8dd38f4b2e0bc",
            "b29a64a4692e483abe7cdd3fa0ce2a33",
            "dab92f1712d0459da27a674b970b42d5"
          ]
        },
        "id": "nTkcF1MALyAs",
        "outputId": "8d9670dd-3dd3-4916-99e0-7e6f138f8ac2"
      },
      "outputs": [],
      "source": [
        "feature_extractor = FeatureExtractor()\n",
        "criterion_content = torch.nn.L1Loss()\n",
        "criterion_content = criterion_content.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZA98DZALyCt",
        "outputId": "c554623d-6c98-4542-f56a-73eb8fe05ca8"
      },
      "outputs": [],
      "source": [
        "feature_extractor.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUTOtNnSLyEi"
      },
      "outputs": [],
      "source": [
        "feature_extractor = feature_extractor.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr81iHX_MpGo",
        "outputId": "9a6e9812-50bf-4879-81d0-04f8a21992ce"
      },
      "outputs": [],
      "source": [
        "for i, data in enumerate(dataloader256, 0):\n",
        "  netEn.zero_grad()\n",
        "  real_cpu = data[0].to(device)\n",
        "  b_size = real_cpu.size(0)\n",
        "  label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "  fixed_noise_new = netEn(real_cpu)\n",
        "  print(fixed_noise_new.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Cg5mEgsEU1C"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "import torch.autograd as autograd\n",
        "import math\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "\n",
        "cuda = bool(torch.cuda.is_available())\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "\n",
        "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
        "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
        "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
        "    d_interpolates = D(interpolates)\n",
        "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "    gradients = autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    return ((gradients.norm(2, dim=1) - 1) ** 2).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsgxhTnvcs4Y",
        "outputId": "3acc0218-8287-4c12-c9c0-67bc2f4cb42d"
      },
      "outputs": [],
      "source": [
        "\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "lambda_gp = 10\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "      for j, data256 in enumerate(dataloader256, 0):\n",
        "\n",
        "        if i==j:\n",
        "          netD.zero_grad()\n",
        "          real_cpu = data[0].to(device)\n",
        "          b_size = real_cpu.size(0)\n",
        "          label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "\n",
        "          real_cpu256 = data256[0].to(device)\n",
        "          b_size256 = real_cpu256.size(0)\n",
        "\n",
        "          encoded = netEn(real_cpu256)\n",
        "\n",
        "\n",
        "          output = netD(real_cpu).view(-1)\n",
        "          errD_real = criterion(output, label)\n",
        "          errD_real.backward()\n",
        "          D_x = output.mean().item()\n",
        "\n",
        "          noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "          fake_new = netG64(encoded)\n",
        "\n",
        "          output_inp = real_cpu256.view(-1)\n",
        "\n",
        "          gradient_penalty = compute_gradient_penalty(netD, real_cpu.data, fake_new.data)\n",
        "          label.fill_(fake_label)\n",
        "          output = netD(fake_new.detach()).view(-1)\n",
        "          errD_fake = criterion(output, label) + lambda_gp * gradient_penalty\n",
        "          errD_fake.backward()\n",
        "          D_G_z1 = output.mean().item()\n",
        "          errD = errD_real + errD_fake + lambda_gp * gradient_penalty\n",
        "          optimizerD.step()\n",
        "\n",
        "          netG64.zero_grad()\n",
        "\n",
        "          loss_real = criterion(netD(real_cpu), label)\n",
        "          loss_fake = criterion(netD(fake.detach()), fake_label)\n",
        "\n",
        "\n",
        "          gen_features = feature_extractor(fake_new)\n",
        "          real_features = feature_extractor(real_cpu)\n",
        "          loss_content = criterion_content(gen_features, real_features.detach())\n",
        "\n",
        "\n",
        "          output = netD(fake_new).view(-1)\n",
        "          errG = ((1e-1 - 1e-5)/(epoch+1))*criterion(output, label) + loss_content\n",
        "          errG.backward()\n",
        "\n",
        "          output_dec = netDec(fake_new).view(-1)\n",
        "          total_err = criterion(output_dec,output_inp)\n",
        "\n",
        "          D_G_z2 = output.mean().item()\n",
        "          optimizerG.step()\n",
        "          if i % 50 == 0:\n",
        "              print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f \\tTotal_Loss: %.4f'\n",
        "                    % (epoch, num_epochs, i, len(dataloader),\n",
        "                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2, total_err))\n",
        "          \n",
        "          G_losses.append(errG.item())\n",
        "          D_losses.append(errD.item())\n",
        "          \n",
        "          if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "              with torch.no_grad():\n",
        "                  fake = netG64(fixed_noise_new).detach().cpu()\n",
        "              img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "              \n",
        "          iters += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npL1PTADcs4a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_9x5Opecs4b"
      },
      "outputs": [],
      "source": [
        "#%%capture\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDmjLzFncs4c"
      },
      "outputs": [],
      "source": [
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GEN_PATH = '/content/Gen_images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv1rR5kkdMAn"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "gen_images = []\n",
        "for img_path in glob.glob(GEN_PATH+'*.png'):\n",
        "    print(img_path)\n",
        "    gen_images.append(mpimg.imread(img_path))\n",
        "\n",
        "columns = 20\n",
        "for i, image in enumerate(gen_images):\n",
        "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset256 = dset.ImageFolder(root=GEN_PATH,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size256),\n",
        "                               transforms.CenterCrop(image_size256),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "dataloader256 = torch.utils.data.DataLoader(dataset256, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "\n",
        "real_batch = next(iter(dataloader256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = 4\n",
        "total_size = 14864\n",
        "train_size = math.ceil(0.7 * total_size)\n",
        "test_size = total_size - train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset, test_dataset = torch.utils.data.random_split(dataloader256, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, 16, 3, 1, 1, bias=False),\n",
        "            nn.ReLU(0.1),\n",
        "            nn.MaxPool2d(3),\n",
        "            nn.Conv2d(16, 8, 3, 1, 1, bias=False),\n",
        "            nn.ReLU(0.1),\n",
        "            nn.MaxPool2d(3),\n",
        "            nn.Conv2d(8, 8, 3, 1, 1, bias=False),\n",
        "            nn.ReLU(0.1),\n",
        "            nn.MaxPool2d(3),\n",
        "            nn.Conv2d(8, 8, 3, 1, 1, bias=False),\n",
        "            nn.ReLU(0.1),\n",
        "            nn.MaxPool2d(3),\n",
        "            nn.Conv2d(8, 6, 3, 1, 1, bias=False),\n",
        "            nn.ReLU(0.1),\n",
        "            nn.MaxPool2d(3),\n",
        "            nn.Conv2d(6, 16, 3, 1, 1, bias=False),\n",
        "            nn.ReLU(0.1),\n",
        "            nn.MaxPool2d(3),\n",
        "            nn.Conv2d(16, 16, 4, 1, 0, bias=False),\n",
        "            nn.Flatten(1),\n",
        "            nn.Linear(64,32),\n",
        "            nn.Linear(32,num_classes),\n",
        "            nn.Softmax()\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clgannet = Classifier(ngpu).to(device)\n",
        "summary(clgannet, (3,256,256))\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    clgannet = nn.DataParallel(clgannet, list(range(ngpu)))\n",
        "    \n",
        "print(clgannet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "optimizer = torch.optim.Adam(clgannet.parameters(), lr = lr,betas=(beta1,beta2), momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):  \n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataset, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = clgannet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    \n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_PATH = './clgannet.pth'\n",
        "torch.save(clgannet.state_dict(), MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_dataset:\n",
        "        images, labels = data\n",
        "        outputs = clgannet(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a693b4244314036ba6d384f64ee3199": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2185f33f8fc64e5aa0a6a458450ffee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66581b66da7e473288a079b5ddc62edd",
              "IPY_MODEL_7e6963a5c09144d48cb4c7e5678c19e6",
              "IPY_MODEL_48ac700288a74cae9f54fd131e2ca317"
            ],
            "layout": "IPY_MODEL_e8919e251123426ca688aa985bd59202"
          }
        },
        "48ac700288a74cae9f54fd131e2ca317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b29a64a4692e483abe7cdd3fa0ce2a33",
            "placeholder": "​",
            "style": "IPY_MODEL_dab92f1712d0459da27a674b970b42d5",
            "value": " 548M/548M [00:23&lt;00:00, 11.8MB/s]"
          }
        },
        "66581b66da7e473288a079b5ddc62edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b126f8c8ce1b42c0865519b200f0b4f0",
            "placeholder": "​",
            "style": "IPY_MODEL_ad2c75e53fb44983bd7d9d8720184db3",
            "value": "100%"
          }
        },
        "7e6963a5c09144d48cb4c7e5678c19e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a693b4244314036ba6d384f64ee3199",
            "max": 574673361,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1eee1fd4c014a8babc8dd38f4b2e0bc",
            "value": 574673361
          }
        },
        "ad2c75e53fb44983bd7d9d8720184db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b126f8c8ce1b42c0865519b200f0b4f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b29a64a4692e483abe7cdd3fa0ce2a33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab92f1712d0459da27a674b970b42d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8919e251123426ca688aa985bd59202": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1eee1fd4c014a8babc8dd38f4b2e0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
